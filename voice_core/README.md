# 🗣️ 语音识别与合成模块（voice_core）

## 模块简介
本模块负责将用户语音转写为文字、将助手回复转换为语音。它是语音交互的核心，支持中文、英文及中英混合输入，目标是实现自然语音唤醒和情感表达。

---

## 核心功能
- 语音转文字（Speech-to-Text）
- 文本转语音（Text-to-Speech）
- 支持多语种（中英文自动识别）
- 支持自定义唤醒词（如“小Z”）
- 支持“人声感”合成播报
- 可配置多个麦克风与扬声器，覆盖多个房间

---

## 唤醒与处理流程
1. 被唤醒词或持续监听触发
2. 语音识别引擎将语音转为文字
3. 传递文字给 GPT 接口或本地逻辑处理
4. 回复文本传入语音合成引擎
5. 播放生成语音，支持跨房间播报

---

## 推荐依赖
- `vosk`：本地语音识别（轻量，无需联网）
- `faster-whisper` 或 `openai-whisper`：高精度语音识别
- `pyttsx3`, `edge-tts`, 或 `gTTS`：语音合成
- `pyaudio` 或 `sounddevice`：音频输入输出支持

---

## 使用方法
```python
from voice_core import listen_and_reply
listen_and_reply()
```

---

## 开发计划
- [x] 本地语音识别（VOSK）
- [x] 英中混合语言处理
- [x] 基础语音合成（gTTS / edge-tts）
- [ ] 情绪识别接口
- [ ] 多房间语音输入输出
- [ ] 支持更换女声/自然语调
- [ ] 唤醒词定制训练
